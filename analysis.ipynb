{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chess_board import chessboard\n",
    "from play import Game\n",
    "from agent_AI import agent_AI\n",
    "from policy_network import PolicyValueNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = 'trained_policy/current_policy_1.model'\n",
    "model2 = 'current_policy_100_org.model'\n",
    "\n",
    "policy1 = PolicyValueNet(model1).policy_value_fn\n",
    "policy2 = PolicyValueNet(model2).policy_value_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "myPlayer = agent_AI(policy1)\n",
    "orgPlayer = agent_AI(policy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Winrate(p1,p2,n_game):\n",
    "    \"\"\"return game result in list [p1 wins, p2 wins, tie]\"\"\"\n",
    "    board =chessboard()\n",
    "    game = Game(board)\n",
    "    result =[0,0,0]\n",
    "    for i in range(n_game):\n",
    "        winner = game.start_play(p1,p2,0,False)\n",
    "        #1 p1, 2 p2, -1 tie\n",
    "        if winner ==1:\n",
    "            result[0]+=1\n",
    "        elif winner==2:\n",
    "            result[1]+=1\n",
    "        else:\n",
    "            result[2]+=1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "-1\n",
      "go back to root\n",
      "63\n",
      "-1\n",
      "go back to root\n",
      "62\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result \u001b[39m=\u001b[39m Winrate(myPlayer,orgPlayer,\u001b[39m10\u001b[39;49m)\n\u001b[0;32m      2\u001b[0m result\n",
      "Cell \u001b[1;32mIn[23], line 7\u001b[0m, in \u001b[0;36mWinrate\u001b[1;34m(p1, p2, n_game)\u001b[0m\n\u001b[0;32m      5\u001b[0m result \u001b[39m=\u001b[39m[\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m]\n\u001b[0;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_game):\n\u001b[1;32m----> 7\u001b[0m     winner \u001b[39m=\u001b[39m game\u001b[39m.\u001b[39;49mstart_play(p1,p2,\u001b[39m0\u001b[39;49m,\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m      8\u001b[0m     \u001b[39m#1 p1, 2 p2, -1 tie\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     \u001b[39mif\u001b[39;00m winner \u001b[39m==\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\97659\\Desktop\\homework\\grad_2023_SPRING\\CSE_546\\final_project\\play.py:33\u001b[0m, in \u001b[0;36mGame.start_play\u001b[1;34m(self, player1, player2, start_player, is_shown)\u001b[0m\n\u001b[0;32m     31\u001b[0m current_player \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mboard\u001b[39m.\u001b[39mcurrent_player\n\u001b[0;32m     32\u001b[0m player_in_turn \u001b[39m=\u001b[39m players[current_player]\n\u001b[1;32m---> 33\u001b[0m move \u001b[39m=\u001b[39m player_in_turn\u001b[39m.\u001b[39;49mget_action(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mboard)\n\u001b[0;32m     34\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mboard\u001b[39m.\u001b[39maction(move)\n\u001b[0;32m     35\u001b[0m \u001b[39mif\u001b[39;00m is_shown:\n",
      "File \u001b[1;32mc:\\Users\\97659\\Desktop\\homework\\grad_2023_SPRING\\CSE_546\\final_project\\agent_AI.py:23\u001b[0m, in \u001b[0;36magent_AI.get_action\u001b[1;34m(self, board, epsilon, return_prob)\u001b[0m\n\u001b[0;32m     21\u001b[0m move_probs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(\u001b[39m64\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(sensible_moves) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m---> 23\u001b[0m     acts, probs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmcts\u001b[39m.\u001b[39;49mget_move(board, epsilon)\n\u001b[0;32m     24\u001b[0m     move_probs[\u001b[39mlist\u001b[39m(acts)] \u001b[39m=\u001b[39m probs\n\u001b[0;32m     25\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_selfplay:\n\u001b[0;32m     26\u001b[0m         \u001b[39m# add Dirichlet Noise for exploration (needed for\u001b[39;00m\n\u001b[0;32m     27\u001b[0m         \u001b[39m# self-play training)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\97659\\Desktop\\homework\\grad_2023_SPRING\\CSE_546\\final_project\\MCTS.py:104\u001b[0m, in \u001b[0;36mMCTS.get_move\u001b[1;34m(self, chessboard, epsilon)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_step):\n\u001b[0;32m    103\u001b[0m     chessboard_copy \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(chessboard)\n\u001b[1;32m--> 104\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mplay(chessboard_copy)\n\u001b[0;32m    106\u001b[0m \u001b[39m# calc the move probabilities based on visit counts at the root node\u001b[39;00m\n\u001b[0;32m    107\u001b[0m act_visits \u001b[39m=\u001b[39m [(act, node\u001b[39m.\u001b[39mn_visits) \u001b[39mfor\u001b[39;00m act, node \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot\u001b[39m.\u001b[39mchildren\u001b[39m.\u001b[39mitems()]\n",
      "File \u001b[1;32mc:\\Users\\97659\\Desktop\\homework\\grad_2023_SPRING\\CSE_546\\final_project\\MCTS.py:48\u001b[0m, in \u001b[0;36mMCTS.play\u001b[1;34m(self, chessboard)\u001b[0m\n\u001b[0;32m     46\u001b[0m     node\u001b[39m.\u001b[39mupdate(\u001b[39m-\u001b[39mleaf_value)\n\u001b[0;32m     47\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 48\u001b[0m     action_probs, leaf_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpolicy(chessboard)\n\u001b[0;32m     49\u001b[0m \u001b[39m# Check for end of game\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     end, winner \u001b[39m=\u001b[39m chessboard\u001b[39m.\u001b[39mgame_end()\n",
      "File \u001b[1;32mc:\\Users\\97659\\Desktop\\homework\\grad_2023_SPRING\\CSE_546\\final_project\\policy_network.py:95\u001b[0m, in \u001b[0;36mPolicyValueNet.policy_value_fn\u001b[1;34m(self, board)\u001b[0m\n\u001b[0;32m     91\u001b[0m current_state \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mascontiguousarray(board\u001b[39m.\u001b[39mcurrent_state()\u001b[39m.\u001b[39mreshape(\n\u001b[0;32m     92\u001b[0m         \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m4\u001b[39m,\u001b[39m8\u001b[39m, \u001b[39m8\u001b[39m))\n\u001b[0;32m     93\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_gpu:\n\u001b[0;32m     94\u001b[0m     log_act_probs, value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpolicy_value_net(\n\u001b[1;32m---> 95\u001b[0m             Variable(torch\u001b[39m.\u001b[39;49mfrom_numpy(current_state))\u001b[39m.\u001b[39;49mcuda()\u001b[39m.\u001b[39mfloat())\n\u001b[0;32m     96\u001b[0m     act_probs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexp(log_act_probs\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mflatten())\n\u001b[0;32m     97\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "result = Winrate(myPlayer,orgPlayer,10)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
